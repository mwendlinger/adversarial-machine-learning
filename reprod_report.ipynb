{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRX5PP3NFfKJ"
   },
   "source": [
    "\n",
    "      \n",
    "      \n",
    "   \n",
    "# G4 - Adversarial Training 2\n",
    "This notebook presents the reproducibility report of our group, where we have two sections each dealing with one of the papers respectively.    \n",
    "We will introduce the basic concepts and frameworks of the paper before showing their empirical findings and our attempts to reproduce them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTkggWknGjle"
   },
   "source": [
    "## First paper: More Data Can Expand the Generalization Gap Between Adversarially Robust and Standard Models - *Lin Chen, Yifei Min, Mingrui Zhang, Amin Karbasi*\n",
    "\n",
    "The first paper deals with the challenge of decreasing the performance gap on natural (non-perturbed) datasets between standard machine learning models and adversarially trained models. Its main point is that the naive approach of simply increasing the training dataset size may not always help in decreasing this gap, in fact it might increase it depending on the strength of the adversary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVasqv02KrVx"
   },
   "source": [
    "### General setting\n",
    "The paper examines the 'cross-generalization gap' (as they call it) under two settings:\n",
    "\n",
    "\n",
    "1.   Binary Classification with Gauss and Bernoulli distribution\n",
    "2.   Linear Regression with Gauss and Poisson distribution\n",
    "\n",
    "In the both cases, we have the following problem setup:\n",
    "\n",
    "![Points](src/cross_gen_gap/graphics/img.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification\n",
    "In Binary Classification, we have datapoints $(x,y) \\in \\mathbb{R}^{d} \\times\\{\\pm 1\\}$, model parameter $w \\in \\mathbb{R}^{d}$ and loss function $\\ell(x, y ; w)=-y\\langle w, x\\rangle$. This means that the paper limits itself to the case of a linear classifier, in which the model is further restricted by $\\|w\\|_{\\infty} \\leq W$, where $W$ is some positive real number.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Model\n",
    "In the Gaussian Model, the datapoints for training and test datasets are generated by a Gaussian distribution, i.e. $y\\sim$ Unif$(\\{\\pm 1\\})$ and $x \\mid y \\sim \\mathcal{N}(y \\mu, \\Sigma)$, where $\\mu(j) \\geq 0$ for $\\forall j \\in[d]$ and $\\Sigma=\\operatorname{diag}\\left(\\sigma(1)^{2}, \\sigma(2)^{2}, \\ldots, \\sigma(d)^{2}\\right)$.     \n",
    "For the empirical studies, the paper simplifies the model by setting $W = d = \\mu = 1$ and $ \\sigma = 2$, in other words it only considers a 1-dimensional case with class centers around 1 and -1 respectively, where the weight $w\\in \\mathbb{R}$ of the model is bounded by $\\|w\\|_{\\infty} \\leq 1$.   \n",
    "To study the cross generalization gap, the authors investigate the performance (test loss) of this model with different values for $\\varepsilon$ and increasing training data sizes $n$ for each of the inspected values of $\\varepsilon$. The graph below visualizes these empirical studies.    \n",
    "\n",
    "The main finding of the paper in this section is that \n",
    "1. if the adversarial strength $\\varepsilon$ is small enough (precise bounds stated in the paper), then there are two stages of the cross generalization gap for increasing training dataset sizes $n$: an initial strictly increasing stage followed by a stage where the gap is strictly decreasing\n",
    "2. if the strength of the adversary is too large, then the cross generalization gap will be strictly increasing for all $n \\in \\mathbb{N}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss | Generalization Gap\n",
    "-|-\n",
    "![Loss](src/cross_gen_gap/graphics/loss_values_gauss.png) | ![Loss](src/cross_gen_gap/graphics/gen_gap_gauss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "<tr>\n",
    "<td> ![Loss](src/cross_gen_gap/graphics/loss_values_gauss.png) </td>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/gen_gap_gauss.png\" alt=\"Cross generalization gap between models trained on adversarially perturbed datasets and standard model\" style=\"width: 380px;\"/> </td>\n",
    "</tr>\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both plots shown above are taken directly from the paper and represent empirical findings we aim to reproduce here.\n",
    "The right figure directly follows from the left one if we simply take the difference between each of the $\\varepsilon$ models and the standard model, respectively. As the loss function and cross generalization gap is defined over expected values, these curves show averages over multiple runs of the training and evaluation process. The paper doesn't state how often they rerun the experiments and if they used some smoothening in plotting the graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to reproduce this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h6l90GuwWvb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfrom google.colab import drive\\nimport os\\n\\ngdrive_path='/content/gdrive/MyDrive/g4-adv-training'\\n\\n# This will mount google drive under 'MyDrive'\\ndrive.mount('/content/gdrive', force_remount=True)\\n# Navigate to our base folder\\nos.chdir(gdrive_path)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If this notebook is being run on Google Colab, uncomment the following lines\n",
    "# In order for this to work, create a folder g4-adv-training on drive and paste the repo contents there\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/g4-adv-training'\n",
    "\n",
    "# This will mount google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# Navigate to our base folder\n",
    "os.chdir(gdrive_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eeLC2373FT7S"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_gen_gap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbin_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Import useful libraries and own code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from src.cross_gen_gap.bin_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc-oeznRII0b"
   },
   "outputs": [],
   "source": [
    "# by uncommenting the lines below, you can try out our setup with different values for eps\n",
    "# and number of repititions; for setting below, this takes about 2min but will be very inaccurate\n",
    "\"\"\"\n",
    "\n",
    "eps_list = [0.0, 0.5, 1.0]\n",
    "n_points = list(range(1, 21,4))\n",
    "adv_test_loss = train_classification_model(eps_list, num_repetition = 50, n_points = n_points, points_step_size=4)\n",
    "plot_class_loss(eps_list, adv_test_loss, training_points=n_points)\n",
    "plot_class_gap(eps_list, adv_test_loss, training_points=n_points)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX9au2KvNrMk"
   },
   "source": [
    "We have the following experiment setup (please have a look at the file `src/cross_gen_gap/bin_classification.py` for reference):\n",
    "* We adversarially train a model for a particular value of $\\varepsilon$ on a dataset of size n where n ranges from 1 to 20\n",
    "* We test this model on a test dataset of size 5000 and save the loss\n",
    "\n",
    "We repeat this experiment 100 times for each chosen value of the adversarial strength and average over the resulting loss values. This experiment is conducted for a Gaussian data sampling and for Bernoulli data sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFLLUL4574-7"
   },
   "source": [
    "# Plot (Gaussian)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "<tr>\n",
    "<tr>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/loss_values_gauss.png\" alt=\"Loss values for different training sizes and epsilon values\" style=\"width: 450px;\"/> </td>  \n",
    "<td> <img src=\"src/cross_gen_gap/graphics/class_loss_gauss_smooth.png\" alt=\"Loss values for different training sizes and epsilon values\" style=\"width: 400px;\"/> </td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/gen_gap_gauss.png\" alt=\"Cross generalization gap between models trained on adversarially perturbed datasets and standard model\" style=\"width: 380px;\"/> </td>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/generalization_gap_bin_class_gauss-1.png\" alt=\"Cross generalization gap between models trained on adversarially perturbed datasets and standard model\" style=\"width: 400px;\"/> </td>\n",
    "</tr>\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss from the paper | Our loss values\n",
    "-|-\n",
    "![Loss](src/cross_gen_gap/graphics/loss_values_gauss.png) | ![Loss](src/cross_gen_gap/graphics/class_loss_gauss_smooth.png)\n",
    "**Generalizetion Gap from the paper** | **Our generalization gap**\n",
    "![Loss](src/cross_gen_gap/graphics/gen_gap_gauss.png) | ![Loss](src/cross_gen_gap/graphics/generalization_gap_bin_class_gauss-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The plots above show our results for the case of Gaussian model classification. \n",
    "We see that our test loss for the standard model converges to -1 as the training set size increases.\n",
    "For most smaller $\\varepsilon$'s, we see that the generalization gap increases first and then falls resulting in a peak somewhere between the training set sizes 5 to 10. This result is consistent with the findings in the paper. However, we observe a different behavior for $\\varepsilon$ ranges between 0.7 and 1, we do not see a decreasing behaviour for larger training set sizes as opposed to the paper plots. This may be due to insufficient number of experiment runs where we were bounded by the runtimes of the training process. The peak for values $\\varepsilon = 0.7$ and $\\varepsilon = 0.9$ can only be faintly seen for training set sizes ranging between 5 and 10.\n",
    "For larger $\\varepsilon$, we see that increasing the number of training points does not close the generalization gap, which is again consistent with what the paper argues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot (Bernoulli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<tr>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/Loss_Bernoulli_paper.png\" alt=\"Loss values for different training sizes and epsilon values(Paper)\" style=\"width: 450px;\"/> </td>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/Class_loss_bern.png\" alt=\"Loss values for different training sizes and epsilon values\" style=\"width: 380px;\"/> </td>\n",
    "</tr>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss from the paper | Our loss values\n",
    "-|-\n",
    "![Loss](src/cross_gen_gap/graphics/Loss_Bernoulli_paper.png) | ![Loss](src/cross_gen_gap/graphics/Class_Loss_Bern.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plots represent the test loss of an adverserially trained model for different values of the signal strength parameter $\\tau$. The lower values of $\\tau$ (0.1 and 0.2) correspond to the strong adversary regime, while the higher ones (0.5 and 0.7) represent the weak adversary case. The value of $\\varepsilon$ is fixed to 0.2 for all the experiments in this section.\n",
    "\n",
    "The plot shown on the left is from the paper, while the one on the right shows the results obtained by us. We are able to reproduce the behavior for the most part, as we observe an initial decline in the loss for larger $\\tau$'s while a steady behavior for smaller $\\tau$'s. In the presentation, we had a spike around values of 140, this was due to plotting issues and did not represent any behaviour of the data, now this is fixed and the values align.\n",
    "Differing from the paper, our graphs are a lot less noisy as we only check for 10 different dataset sizes as. This suffices to see the trend proposed in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot (Linear Regression - Gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<tr>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/Lin_Reg_Loss_paper.png\" alt=\"Loss values for different training sizes and epsilon values(Paper)\" style=\"width: 450px;\"/> </td>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/Lin_Reg_Loss_Values-1.png\" alt=\"Loss values for different training sizes and epsilon values\" style=\"width: 380px;\"/> </td>\n",
    "</tr>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss from the paper | Our loss values\n",
    "-|-\n",
    "![Loss](src/cross_gen_gap/graphics/Lin_Reg_Loss_paper.png) | ![Loss](src/cross_gen_gap/graphics/Lin_Reg_Loss_Values-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to the best adverserially robust model for the case of linear regression is given by the closed form expression:  \n",
    " $$ \\begin{aligned} \n",
    "w_{n}^{\\mathrm{rob}} &=\\underset{w \\in \\mathbb{R}^d}{\\arg \\min } \\frac{1}{n} \\sum_{i=1}^{n} \\left(|y_i - <w,x_i>| + \\varepsilon\\sum_{j=1}^{d}|w_j|\\right)^2 \\end{aligned}$$\n",
    "\n",
    "Using this result, we emulate models for different $\\varepsilon$'s using different training sets with 1 to 20 samples. The left plot showing the variation of test loss with the number of training samples for different values of $\\varepsilon$ is taken from the paper while the right figure is obtained through our experiments. The trend for different $\\varepsilon$'s is similar in both the graphs, except for the behavior of the standard model ($\\varepsilon$ = 0) whose curve lies above the rest of the curves in the reproduced version. As argued in the paper, the test loss for the standard model should converge to 0 on incrementing the number of training samples to 20. In our case, this convergence is a bit delayed and is not evident with just 20 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot (Linear Regression) - Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<tr>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/poisson_smaller_e_paper.png\" alt=\"Loss values for different training sizes and epsilon values(Paper)\" style=\"width: 500px;\"/> </td>\n",
    "<td> <img src=\"src/cross_gen_gap/graphics/poisson_smaller_e.png\" alt=\"Loss values for different training sizes and epsilon values\" style=\"width: 380px;\"/> </td>\n",
    "</tr>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss from the paper | Our loss values\n",
    "-|-\n",
    "![Loss](src/cross_gen_gap/graphics/poisson_smaller_e_paper.png) | ![Loss](src/cross_gen_gap/graphics/poisson_smaller_e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graphs show the result for Linear Regression with data sampled from the Poisson distribution.\n",
    "The loss for the standard model($\\varepsilon$ = 0) shows a consistent behavior in both the graphs. However, for other values of $\\varepsilon$, we see that the behavior diverges from the paper. The test loss in the reproduced graph shows an initial upward trend followed by convergence at values much higher than the ones in the plot from the original paper. This will be investigated in the next experiments we will conduct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The paper points out that depending on the strength of the adversary, it will not always help to increase the size of the training dataset to adversarially train models and obtain a good performance on natural/ benign test data. This main trend is also visible in our own experiments. In scenarios with a medium adversary, our results are mory blurry due to the limited amount of repetitions of the experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Extensions\n",
    "\n",
    "The data's empirical studies focus on the one-dimensional case for Binary Classification and Linear Regression. A first step will be to extend this to higher-dimensional data and then go to more complex models and see how they differ. Also, different approaches like FGSM and PGD will be interesting to compare in this regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second paper: Adversarial Robustness vs. Model Compression, or Both? - *Shaokai Ye, Kaidi Xu, Sijia Liu, Jan-Henrik Lambrechts, Huan Zhang, Aojun Zhou, Kaisheng Ma, Yanzhi Wang, Xue Lin*\n",
    "\n",
    "The second paper tackles the dilemma od adversarial traning where achieving adversarial robustness requires significant capacity of the network in order to achieve competative performance. This may limit its use for security-critical scenarios especially in resource constrained application systems. In order to address this issue, the authors propose a framework of concurrent adversarial training and weight pruning that enables model compression while still preserving the adversarial robustness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General setting\n",
    "\n",
    "Alternating direction method of multipliers (ADMM) allows for concurrent adversarial training and weight pruning. This framework is built on the augmented Lagrangian of an equality constrained problem. Consequently, the problem is decompossed into two subproblems that are solved iteratively.\n",
    "It is used in combination with **filter pruning scheme**, which is a common pruning choice to \n",
    "facilitate the implementation of sparse neural networks on hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setting\n",
    "\n",
    "In Table1, we present LeNet network tested in the paper with its model architectures specified by the width scaling factor $\\omega$. By using different $\\omega$ values one can obtain adversarial baselines of different complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text {LeNet} | 2 * \\omega, 4* \\omega, FC (196*\\omega, 64*\\omega), FC (64*\\omega,10) $$\n",
    "\n",
    "Table1. Network stucture used in original experiments where $FC$ means fully coonected layer.\n",
    "Other numbers denote the numbers of filters in convolutional layers. Here $\\omega$ is the scaling factor of the LeNet network. Each layer is equally scaled with $ \\omega $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experimental pipeline is summarized in the flowchart bellow.\n",
    " After obtaining an $\\omega$ specific adversarial baseline a compression via weight pruning is applied. The compression rate is controled with the prune ratios. These ratios are only defined for the first two convolutional layers. In context of filter fruning scheme this means we prune 80% and 94.7% of weights in first and second convolutional layer respectively. \n",
    "\n",
    "Note: The prune ratio values of 0.8 and 0.947 are for illustration purposes. For the matter of fact, these values were predifined in the paper repo's config file withouht any further explanation from the authors side.    \n",
    "We use these values as a starting point in our own experiments to closely examine their relationship to the compression rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![summary of the approach](src/model_compression/graphics/summary_approach.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By leveraging the ADMM approach, it turns out that the model obtained after the compression step preserves adversarial robustness compared to the starting baseline. This can be seen from Table2 which summarizes original paper results carried out on MNIST. \n",
    "\n",
    "For $\\omega$=16 adversarial baseline (99.02%/94.65%) one can obtain a pruned model with the target size of $\\omega$=8 via compression rate of 2 (99.01%/95.44%) or even much smaller model of size $\\omega$=1 via stronger compression rate of 16 (96.19%/87.79%) while still achieving competitive natural test accuracy/adversarial test accuracy. We can notice that this behavior is present when going from small to large compression rate across all $\\omega$ (red arrow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST Experiment](src/model_compression/graphics/mnist_experiment_summary.png)\n",
    "\n",
    " Table2. Natural test/adversarial test accuracy on MNIST of naturally trained model with different size $\\omega$\t(second column),  \n",
    " adversarially trained model with different size $ \\omega$ (third column), concurrent adversarial training and weight pruning from a large size to a small size compression rate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Discussion\n",
    "\n",
    "In this section we present our own experimental results on MNIST dataset using LeNet architecture specified with Table1. We report natural test/adversarial test accuracy for subset of $\\omega$ that is 1, 2, 4 and 16. Before we present our findings on concurrent adversarial training and weight pruning we shortly showcase obtained results for natural and adversarial baseline across above-mentioned $\\omega$ values (Table3). We note that there is no significant deviation between our experiment and original results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST Experiment](src/model_compression/graphics/experiment_vanilla.png)\n",
    "Table3. Validating natural and adversarial baseline test accuracies across target $\\omega$ values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first ADMM experiment we direct our focus towards predifined prune ratio values and examining \n",
    "how do they influence the compression rate acrross different $\\omega$ (Table4). \n",
    "\n",
    "Main observations:\n",
    "\n",
    "*  with given prune ratios we achieve almost ~16x times compression rate (15.407) for $\\omega$=16, \n",
    "meaning for starting $\\omega$=16 the size after pruning should be close to $\\omega$=1 and when we \n",
    "compare achieved natural test/adversarial test accuracy to corresponding one from the paper we see they \n",
    "are indeed in a really close range (our experiment: 97.26/87.94 paper: 96.19/87.79)\n",
    " \n",
    "*  according to the paper supposed/\"allowed\" compression rate for $\\omega$=4 should be 4 and 2 but we \n",
    "got ~14x compression rate (13.6); same holds for $\\omega$=2 where only possible compression rate should \n",
    "be 2 but we obtained ~7x compression rate\n",
    "\n",
    "Main conclusion:\n",
    "\n",
    "* high prune ratio values lead to high compression rates across different $\\omega$ which gives us a \n",
    "search direction for further analysis \n",
    "\n",
    "Next, we continue with our experiments in order to demistify second observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"src/model_compression/graphics/experiment_I.png\" align-center width=\"900\"/-->\n",
    "![MNIST Experiment](src/model_compression/graphics/experiment_I.png)\n",
    "Table4. Influence of conv1: 0.8 and conv2: 0.947 prune ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our second experiment we investigate influence of different prune ratio values for fixed $\\omega$. Here we define two settings, first one with the default prune ratio and second setting with its halved version (Table5).\n",
    "\n",
    "Main observation:\n",
    "* with setting II we obtain compression rate of 2x whose output matches one from the Table2 (our experiment 11.35/11.35 paper: 11.35/11.35)\n",
    "\n",
    "Main conclusion:\n",
    "* different prune ratios lead to different compression rates but same output in terms of natural test/advesarial test accuracy (for $\\omega$=2)\n",
    "\n",
    "In order to check whether this conclusion holds in general we conduct experiment under the same settings but for $\\omega$=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"src/model_compression/graphics/experiment_II.png\" align-center width=\"900\"/-->\n",
    "![MNIST Experiment](src/model_compression/graphics/experiment_II.png)\n",
    "Table5. Influence of different prune ratios for $ \\omega  = 2$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analysing Table6 we can see that for setting II we obtain ~2x compression rate (1.87), meaning for starting $\\omega$=16 the size after the pruning should be close to $\\omega$=8 and when we compare achieved test accuracies with ones from the Table2 we indeed see that they almost exactly match. \n",
    "(exp: 99.01/93.23 paper: 99.01/95.44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"src/model_compression/graphics/experiment_III.png\" align-center width=\"900\"/-->\n",
    "![MNIST Experiment](src/model_compression/graphics/experiment_III.png)\n",
    "Table6. Influence of different prune ratios for } $\\omega = 16$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further continue with exploration of prune ratio space and repeat previous experiment but with the aditional setting, that is we wanted to observe what kind of change brings prune ratio value inbetween two previous ones (Table7). \n",
    "\n",
    "Main observation:\n",
    "\n",
    "* by taking 75% of the default prune ratio we obtain ~3.3 compression rate 98.79/93.30 ; the closest value from the paper is 4x compression rate that is 98.87/94.77\n",
    "* by decreasing the value of prune ratios (I->II->III) we achieve smaller compression rate which is consistent with the main premise of the paper (reference to the red arrow from the Table2)\n",
    "\n",
    "Main conclusion:\n",
    "\n",
    "* eventhough we didn't achieve exact 16x, 4x and 2x compression rates, results are still comperable <br>\n",
    "(our experiment: 97.26/87.94 for 15.4x; paper: 96.19/87.79 for 16x  <br>\n",
    " our experiment: 98.79/93.30 for 3.34x; paper: 98.87/94.77 for 4x <br>\n",
    " our experiment: 99.01/93.23 for 1.87x; paper: 99.01/95.44 for 2x)\n",
    " \n",
    "In the following experiment we took prune ratio values inbetween setting I and setting II from Table7 in order to validate results for 8x compression rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"src/model_compression/graphics/experiment_IV.png\" align-center width=\"900\"/-->\n",
    "![MNIST Experiment](src/model_compression/graphics/experiment_IV.png)\n",
    "Table7. Influence of three different prune ratios for $\\omega = 16 $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main observations from fifth experiment (Table 8):\n",
    "\n",
    "* by taking the prune ratio inbetween the default one and its 3/4 version (setting II) we achieve 5.7x compression rate (98.62/94.07) which is not exactly the same as 8x compression rate (98.07/89.95) but it follows the main premise of the paper meaning if we would increase the prune ratio values we would get closser to 8x\n",
    "\n",
    "Main conclusion:\n",
    "\n",
    "* although we didn't achieve exact 16x, 8x, 4x and 2x compression rates, results are still comperable \n",
    "\n",
    "By closely examining these four different prune ratio settings we managed to obtain rough borders of search space for particular compression rate. To validate this, we conduct additional experiment for $\\omega$=4 with the goal to achieve 4x and 2x compression rates. For the former one we narrow down our search inbetween setting II and setting III and for later one inbetween setting III and stting IV. Results are presented in Table9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"src/model_compression/graphics/experiment_V.png\" align-center width=\"900\"/-->\n",
    "![MNIST Experiment](src/model_compression/graphics/experiment_V.png)\n",
    "Table8. Influence of four different prune ratios for $\\omega = 16$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main observations from sixt experiment (Table9):\n",
    "\n",
    "* with setting I we achieve ~4x times compression rate (3.88) for $\\omega$=4, meaning for starting $\\omega$=4 the size after pruning is close to $\\omega$=1\n",
    "(our experiment: 96.28/91.34 paper: 96.22/89.41)\n",
    "\n",
    "* with setting II we achieve ~2x times compression rate (2.26) for $\\omega$=4, meaning for starting $\\omega$=4 the size after pruning is $\\omega$=2\n",
    "(our experiment: 97.30/90.95 paper: 97.68/91.77)\n",
    "\n",
    "Main conclusion:\n",
    "\n",
    "* by adopting search guidelines from the fifth experiment we managed to validate findings for $\\omega$=4 as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"src/model_compression/graphics/experiment_VI.png\" align-center width=\"900\"/-->\n",
    "![MNIST Experiment](src/model_compression/graphics/experiment_VI.png)\n",
    "Table9. Influence of different prune ratios for $\\omega = 4$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Note: All conducted experiments can be repeated by running coresponding call from run.sh.example file (`/src/model_compression/Robustness-Aware-Pruning-ADMM/ADMM_examples/mnist`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In summary, the value of weight pruning is essential in the adversarial training setting: it is possible to acquire a network of small model size (by weight pruning) with both high natural test accuracy and adversarial test accuracy. We saw that for smaller values of prune ratios we obtain smaller compression rates and vice versa i.e. there is a positive correlation between prune ratios and compression rate accross different $\\omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible directions of paper extension "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the ratio between their ADMM approach and just using adversarial training once\n",
    "and pruning afterwards? <br>\n",
    "* Use different pruning schemes and see how this compares <br>\n",
    "* Pruning is only done for conv layers, what about other models/ datasets/ layers?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "reprod_report.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "50acd197fc84a0c8309eb2639637c21c62a2d6bdd21c89688f49159691d4506b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
